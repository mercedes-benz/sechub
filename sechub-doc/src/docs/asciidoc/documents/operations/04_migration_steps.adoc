// SPDX-License-Identifier: MIT
=== Migration steps

==== Database
[WARNING]
====
Normally all updates in database are done by our flyway script automatically!

It is very uncommon to do something manually here. Every manual changes will be described why no
automation was possible!
====

[options="header",cols="1,3,4,4"]
|===
| Nr.                    | What                                                              | Why manual?                                           | Apply to version   
//------------------------------------------------------------------------------------------------------------------------------------------------------------------------
| {counter:migrationNr}  | <<section-migration-spring-batch-477,post handle CVE-2020-5411>>  | Table to update does not exist on new started servers | Initial run < v0.19.0-server

|===
    

[[section-migration-spring-batch-477]]
===== Post handle CVE-2020-5411 

====== Update job execution context to new format

Script to prepare old jobs for Spring batch CVE-2020-5411 changes
  
With Server v0.19.0 we upgraded our Spring Boot dependencies footnote:update_0_19_0[https://github.com/Daimler/sechub/issues/472] but this led to cancelation problems on older jobs - 
this led to problems when deleting older jobs still running.footnote:problem_499[https://github.com/Daimler/sechub/issues/499]

The solution is to execute following `SQL` script on all environments:
[source,sql]
----
UPDATE batch_job_execution_context SET short_context='{"@class":"java.util.HashMap"}' WHERE short_context ='{}' <1>
----
<1> Migrate old execution context JSON to correct format: an empty `HashMap`



Unfortunately it is not possible to automatically migrate the data by `flyway` script, because this would fail any new started server, because
a flyway update script would lead to:

``` java
Caused by: org.h2.jdbc.JdbcSQLSyntaxErrorException: Table "BATCH_JOB_EXECUTION_CONTEXT" not found; SQL statement:
```

====== Update step execution context to new format
Additionally we need to update the step context data as well

[source,sql]
----
-- check for entries with old format
select sc.short_context, count(*) from batch_job_execution_params p
inner join batch_job_execution e on e.job_execution_id=p.job_execution_id
inner join batch_job_execution_context c on c.job_execution_id= e.job_execution_id
inner join batch_step_execution se on se.job_execution_id = e.job_execution_id
inner join batch_step_execution_context sc on sc.step_execution_id = se.step_execution_id
group by sc.short_context

--- execute update when former query has old entries...
update batch_step_execution_context sc set short_context='{"@class":"java.util.HashMap","batch.taskletType":"com.daimler.sechub.domain.schedule.batch.ScanExecutionTasklet","batch.stepType":"org.springframework.batch.core.step.tasklet.TaskletStep"}'
where sc.short_context = '{"batch.taskletType":"com.daimler.sechub.domain.schedule.batch.ScanExecutionTasklet","batch.stepType":"org.springframework.batch.core.step.tasklet.TaskletStep"}' <1>

-- check again for entries in old format
select sc.short_context, count(*) from batch_job_execution_params p
inner join batch_job_execution e on e.job_execution_id=p.job_execution_id
inner join batch_job_execution_context c on c.job_execution_id= e.job_execution_id
inner join batch_step_execution se on se.job_execution_id = e.job_execution_id
inner join batch_step_execution_context sc on sc.step_execution_id = se.step_execution_id
group by sc.short_context


----
<1> Migrate old execution context JSON to correct format: with `HashMap` as class

====== Cancel your old running jobs

When you have some still running jobs - for example because of a former database connection pool problem -
you can now cancel the old jobs without any problems. 

