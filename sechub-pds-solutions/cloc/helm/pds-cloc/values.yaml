# SPDX-License-Identifier: MIT

# This is just a sample values file.

# Number of SecHub server instances to spin up
replicaCount: 1

image:
    registry: "ghcr.io/mercedes-benz/sechub/pds-cloc:latest"
    tag: "latest"
    # Optional: If your image is in a private registry, you can specify pull secrets defined in k8s
    #   Docs: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    #   Example:
    # imagePullSecrets: |-
    #   - name: sechub-pull-secret
    #   - name: sps2

pds:
    config:
        execute:
            # Maximum queue size of pds
            queueMax: 10
            # Number of parallel threads for processing
            workerThreadCount: 5
    # Print alive status every minute
    heartbeatLogging: "true"
    logging:
        type:
            # loggingType (optional): See https://mercedes-benz.github.io/sechub/latest/sechub-operations.html#logging-2
            # https://github.com/mercedes-benz/sechub/blob/develop/sechub-server/src/main/resources/logback-spring.xml
            enabled: false
            appenderName: "LOGSTASH_JSON"
    debug:
        # Automatically cleans workspace. Disable for debugging if you need to look at the files
        keepReportsInWorkspace: false
    javaDebug:
        # Enable Java debugging
        enabled: false
    # When set to true, then the container's run.sh script will keep running for 2h on SecHub server exit.
    # Useful for analyzing server crashes. In all other cases: set to `false`.
    keepContainerAliveAfterPDSCrashed: false

users:
    # PDS user for scanning
    technical:
        id: "techuser"
        apiToken: "<api token of techuser>"
    # PDS user with admin permissions
    admin:
        id: "admin"
        apiToken: "<api token of admin user>"

storage:
    local:
        # No shared storage - only for standalone SecHub server (stores into local /tmp)
        enabled: true
    s3:
        # Use S3 as shared storage backend
        enabled: false
        endpoint: "https://<minio-or-s3-server>:<port>"
        bucketname: "<my-bucketname>"
        accesskey: "<my-accesskey>"
        secretkey: "<my-secretkey>"
    sharedVolume:
        # Use a shared filesystem as storage backend
        enabled: false
        upload:
            dir: "/mount/nfs/shares/<sharename>"

database:
    postgres:
        enabled: false
        connection: "jdbc:postgresql://database:5432/pds"
        username: "cloc"
        password: "<password-of-db-user>"

networkPolicy:
    # Enables networkaccess from the sechub-server
    enabled: false
    ingress:
    - from:
        - podSelector:
            matchLabels:
                name: sechub-server
        - podSelector:
            matchLabels:
                name: sechub-adminserver
